{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation \n",
    "\n",
    "This notebook is going to include all the models which are build using Neurol Networks approach. \n",
    "I specified some bunch of models that I am going to deploy. \n",
    "\n",
    "- to do: Models will be stayed here ! Dont forget !  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We know that effectively exercising your legs ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stressed out? ðŸ˜©\\r\\nTired? ðŸ˜´\\r\\nWorn down? ðŸ˜°\\r\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Time to get rockin' and *foam* rollin' ! Last ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@that_zach_berg Hi Zach, can you please DM us?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@iam_rahulsingh @vikasjain1977 Hi, thank you f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  target\n",
       "0           0  We know that effectively exercising your legs ...       0\n",
       "1           1  Stressed out? ðŸ˜©\\r\\nTired? ðŸ˜´\\r\\nWorn down? ðŸ˜°\\r\\...       0\n",
       "2           2  Time to get rockin' and *foam* rollin' ! Last ...       0\n",
       "3           3  @that_zach_berg Hi Zach, can you please DM us?...       0\n",
       "4           4  @iam_rahulsingh @vikasjain1977 Hi, thank you f...       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"../datasets/deep_data_merged_all_class.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>@chriskrieger91 Hi, thanks for reaching out! W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23615</th>\n",
       "      <td>4272</td>\n",
       "      <td>New episode of the @JalenRose: Renaissance Man...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17142</th>\n",
       "      <td>2680</td>\n",
       "      <td>Gordon Ramsay Hellâ€™s Kitchen will open in Chic...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>468</td>\n",
       "      <td>N95s, which seal tighter to the face, offer be...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19789</th>\n",
       "      <td>446</td>\n",
       "      <td>From exorcisms to weddings â€” the #Grammys have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  target\n",
       "644           644  @chriskrieger91 Hi, thanks for reaching out! W...       0\n",
       "23615        4272  New episode of the @JalenRose: Renaissance Man...       5\n",
       "17142        2680  Gordon Ramsay Hellâ€™s Kitchen will open in Chic...       4\n",
       "9962          468  N95s, which seal tighter to the face, offer be...       2\n",
       "19789         446  From exorcisms to weddings â€” the #Grammys have...       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = data.sample(frac=1, random_state=42) \n",
    "train_df_shuffled.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4976\n",
       "2    4968\n",
       "5    4954\n",
       "4    4881\n",
       "1    4829\n",
       "0    4665\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 3 (real disaster)\n",
      "Text:\n",
      "Porsche hits the gas on synthetic fuel with $75M investment https://t.co/SmZjrycFWS by @jaclyntrop\n",
      "\n",
      "---\n",
      "\n",
      "Target: 2 (real disaster)\n",
      "Text:\n",
      "Jury to weigh fate of 4 men charged in Michigan governor kidnapping plot https://t.co/KcyKPLfftj https://t.co/LmhZy9vujB\n",
      "\n",
      "---\n",
      "\n",
      "Target: 2 (real disaster)\n",
      "Text:\n",
      "Children as young as 8 should be screened for anxiety: US task force https://t.co/fGCZyK8NuE https://t.co/IoKuwi6OoF\n",
      "\n",
      "---\n",
      "\n",
      "Target: 2 (real disaster)\n",
      "Text:\n",
      "Democrats blame messaging for their political problems https://t.co/4RByV8fhLz https://t.co/GvqnRrEfH1\n",
      "\n",
      "---\n",
      "\n",
      "Target: 2 (real disaster)\n",
      "Text:\n",
      "Official review of Trump White House phone logs from January 6 finds record is complete https://t.co/prpLZHOjL7\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "random_index = random.randint(0, len(data) - 5) \n",
    "\n",
    "for  _, text, target in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples():\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1,\n",
    "                                                                            random_state=42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26345,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting text into numbers\n",
    "\n",
    "## Text vectorization (tokenization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweet baÅŸÄ±na kelime sayÄ±sÄ± \n",
    "round( \n",
    "    sum(\n",
    "        [len(i.split()) for i in train_sentences]\n",
    "    ) / len(train_sentences)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000 \n",
    "max_length = 18 \n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length, \n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 18), dtype=int64, numpy=\n",
       "array([[109,   9,   5,   1,   7,  79,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"There is a flood in my suburb!\" \n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9059e48bf3b0ccbf418267d63bd69884bf8e25702a60f044a5610720066f9972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
